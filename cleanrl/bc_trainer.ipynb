{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import (\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Iterable,\n",
    "    Iterator,\n",
    "    Mapping,\n",
    "    Optional,\n",
    "    Tuple,\n",
    "    Type,\n",
    "    Union,\n",
    ")\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../cleanrl/')\n",
    "from radar_maps.env.radar_map_double_integrator import RadarMap_DoubleIntegrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/lucas/workspace/cleanrl/cleanrl/data_multimodal/\"\n",
    "data_num = 1\n",
    "num_mode = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectory:\n",
    "    def __init__(self, obs, actions):\n",
    "        self.obs = obs\n",
    "        self.actions = actions\n",
    "\n",
    "        \n",
    "class TrajDataset(Dataset):\n",
    "    def __init__(self, trajs):\n",
    "        states = []\n",
    "        actions = []\n",
    "        for traj in trajs:\n",
    "            states.append(traj.obs)\n",
    "            actions.append(traj.actions)\n",
    "        self.states = np.concatenate(states, axis=0)\n",
    "        self.actions = np.concatenate(actions, axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.states.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = dict()\n",
    "        sample['state'] = self.states[idx]\n",
    "        sample['action'] = self.actions[idx]\n",
    "        return sample\n",
    "    \n",
    "    def add_traj(self, traj=None, states=None, actions=None):\n",
    "        if traj is not None:\n",
    "            self.states = np.concatenate((self.states, traj.obs), axis=0)\n",
    "            self.actions = np.concatenate((self.actions, traj.actions), axis=0)\n",
    "        else:\n",
    "            self.states = np.concatenate((self.states, states), axis=0)\n",
    "            self.actions = np.concatenate((self.actions, actions), axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_chunk(path, num_points=3):\n",
    "    len_path = len(path)\n",
    "    if len_path >= num_points:\n",
    "        return list(np.hstack(path[:num_points]))\n",
    "    \n",
    "    path_patched = list(np.hstack(path))\n",
    "    for _ in range(num_points-len_path):\n",
    "        path_patched.extend(list(path[-1]))\n",
    "    # print(\"Patched path: \", path_patched)\n",
    "    return path_patched\n",
    "\n",
    "\n",
    "def get_radar_heat_map(state, radar_locs, img_size, radar_detection_range, grid_size):\n",
    "    radars_encoding = np.zeros((img_size, img_size))\n",
    "    theta = np.arctan2(state[3], state[1])\n",
    "    # theta = 0.0\n",
    "    loc_to_glob = np.array([[np.cos(theta), -np.sin(theta), state[0]],\n",
    "                            [np.sin(theta), np.cos(theta), state[2]],\n",
    "                            [0., 0., 1.]])\n",
    "    glob_to_loc = np.linalg.inv(loc_to_glob)\n",
    "    # print(glob_to_loc)\n",
    "    for radar_loc in radar_locs:\n",
    "        if abs(state[0] - radar_loc[0]) < radar_detection_range or abs(state[2] - radar_loc[1]) < radar_detection_range:\n",
    "            # print(\"Radar global: \", radar_loc)\n",
    "            glob_loc_hom = np.array([radar_loc[0], radar_loc[1], 1])\n",
    "            local_loc_hom = np.dot(glob_to_loc, glob_loc_hom)\n",
    "            radars_loc_coord = local_loc_hom[:2]\n",
    "            # print('Global: ', radar_loc)\n",
    "            # print(\"Local: \", radars_loc_coord)\n",
    "            # print(\"Radars local coord: \", radars_loc_coord)\n",
    "            y_grid = np.rint((radars_loc_coord[1]) / grid_size) \n",
    "            x_grid = np.rint((radars_loc_coord[0]) / grid_size) \n",
    "            # print(\"Grid index: \", [x_grid, y_grid])\n",
    "            # print()\n",
    "            for i in range(-int(img_size/2), int(img_size/2)):\n",
    "                for j in range(-int(img_size/2), int(img_size/2)):\n",
    "                    radars_encoding[int(i + img_size/2), int(j + img_size/2)] += np.exp((-(x_grid - i)**2 - (y_grid - j)**2)/2.0)*1e6\n",
    "\n",
    "    plt.imsave('heat_map.jpg', radars_encoding.T, cmap='hot', origin='lower')\n",
    "    heat_map_img = plt.imread('heat_map.jpg')\n",
    "\n",
    "    return heat_map_img\n",
    "\n",
    "def generate_training_data(traj, ctr, path_mm, radars, detection_range, grid_size, v_lim, u_lim):\n",
    "    observations = []\n",
    "    actions = []\n",
    "    for i in range(len(traj)):\n",
    "        x_cur = traj[i]\n",
    "\n",
    "        heat_map_img = get_radar_heat_map(x_cur, radars, 2*int(detection_range/grid_size), detection_range, grid_size)\n",
    "        # print(heat_map_img.shape)\n",
    "        x_cur_normalized = np.array([x_cur[0]/1200.0, x_cur[1]/v_lim, x_cur[2]/1200.0, x_cur[3]/v_lim])\n",
    "\n",
    "        observation = {\"state\": x_cur_normalized, \"img\": heat_map_img}\n",
    "        observations.append(observation)\n",
    "        if i < len(traj) - 1:\n",
    "            action_prediction = []\n",
    "            for m in range(num_mode):\n",
    "                action_prediction.extend(ctr[i, 2*m:2*(m+1)]/u_lim)\n",
    "                path_tmp = path_mm[num_mode*i + m]\n",
    "                path_tmp = [x / 1200.0 for x in path_tmp]\n",
    "                # print(path_tmp)\n",
    "                action_prediction.extend(get_path_chunk(path_tmp))\n",
    "            actions.append(action_prediction)\n",
    "    \n",
    "    return np.array(observations), np.array(actions)\n",
    "\n",
    "def process_data(detection_range, grid_size, v_lim, u_lim):\n",
    "    bc_data = []\n",
    "    for i in range(data_num):\n",
    "        print(\"Processing data: \", i)\n",
    "        traj = np.load(data_path + f'state_traj_{i}.npy')\n",
    "        control = np.load(data_path + f'control_traj_{i}.npy')\n",
    "        radar_config = np.load(data_path + f'radar_config_{i}.npy')\n",
    "\n",
    "        with open(data_path+ f'nominal_path_multimodal_{i}.pkl', 'rb') as handle:\n",
    "            path_mm = pickle.load(handle)\n",
    "\n",
    "        obs, acts = generate_training_data(traj, control, path_mm, radar_config, detection_range, grid_size, v_lim, u_lim)\n",
    "        bc_traj = Trajectory(obs, acts)\n",
    "        bc_data.append(bc_traj)\n",
    "    return TrajDataset(bc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
